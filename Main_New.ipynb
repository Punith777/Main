{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91016903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "218dbaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2568 images belonging to 2 classes.\n",
      "Found 135 images belonging to 2 classes.\n",
      "Found 679 images belonging to 2 classes.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 6272)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.6719\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82031, saving model to best_model.h5\n",
      "80/80 [==============================] - 80s 957ms/step - loss: 0.6028 - accuracy: 0.6719 - val_loss: 0.4359 - val_accuracy: 0.8203\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.4213 - accuracy: 0.8095\n",
      "Epoch 2: val_accuracy improved from 0.82031 to 0.89062, saving model to best_model.h5\n",
      "80/80 [==============================] - 76s 944ms/step - loss: 0.4213 - accuracy: 0.8095 - val_loss: 0.2854 - val_accuracy: 0.8906\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.3091 - accuracy: 0.8715\n",
      "Epoch 3: val_accuracy did not improve from 0.89062\n",
      "80/80 [==============================] - 75s 945ms/step - loss: 0.3091 - accuracy: 0.8715 - val_loss: 0.2836 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2469 - accuracy: 0.8994\n",
      "Epoch 4: val_accuracy improved from 0.89062 to 0.92969, saving model to best_model.h5\n",
      "80/80 [==============================] - 77s 955ms/step - loss: 0.2469 - accuracy: 0.8994 - val_loss: 0.1912 - val_accuracy: 0.9297\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.2002 - accuracy: 0.9219\n",
      "Epoch 5: val_accuracy did not improve from 0.92969\n",
      "80/80 [==============================] - 77s 957ms/step - loss: 0.2002 - accuracy: 0.9219 - val_loss: 0.1823 - val_accuracy: 0.9219\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1601 - accuracy: 0.9377\n",
      "Epoch 6: val_accuracy improved from 0.92969 to 0.94531, saving model to best_model.h5\n",
      "80/80 [==============================] - 76s 952ms/step - loss: 0.1601 - accuracy: 0.9377 - val_loss: 0.1414 - val_accuracy: 0.9453\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1330 - accuracy: 0.9523\n",
      "Epoch 7: val_accuracy did not improve from 0.94531\n",
      "80/80 [==============================] - 77s 963ms/step - loss: 0.1330 - accuracy: 0.9523 - val_loss: 0.2185 - val_accuracy: 0.8906\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.1082 - accuracy: 0.9590\n",
      "Epoch 8: val_accuracy improved from 0.94531 to 0.96094, saving model to best_model.h5\n",
      "80/80 [==============================] - 76s 948ms/step - loss: 0.1082 - accuracy: 0.9590 - val_loss: 0.1026 - val_accuracy: 0.9609\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0829 - accuracy: 0.9724\n",
      "Epoch 9: val_accuracy did not improve from 0.96094\n",
      "80/80 [==============================] - 76s 946ms/step - loss: 0.0829 - accuracy: 0.9724 - val_loss: 0.1430 - val_accuracy: 0.9609\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - ETA: 0s - loss: 0.0797 - accuracy: 0.9704\n",
      "Epoch 10: val_accuracy did not improve from 0.96094\n",
      "80/80 [==============================] - 76s 948ms/step - loss: 0.0797 - accuracy: 0.9704 - val_loss: 0.1444 - val_accuracy: 0.9453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PUNITH KUMAR\\AppData\\Local\\Temp\\ipykernel_17912\\1716776107.py:69: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  test_loss, test_accuracy = model.evaluate_generator(test_generator, steps=test_generator.samples // test_generator.batch_size)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1162\n",
      "Test Accuracy: 0.9524\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.preprocessing.image' has no attribute 'load_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Make predictions on a sample image\u001b[39;00m\n\u001b[0;32m     76\u001b[0m sample_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPUNITH KUMAR\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mBrain_Tumour_Detection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHealthey\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mNot Cancer  (887).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 77\u001b[0m sample_image \u001b[38;5;241m=\u001b[39m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_img\u001b[49m(sample_image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m))\n\u001b[0;32m     78\u001b[0m sample_image_arr \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mimg_to_array(sample_image)\n\u001b[0;32m     79\u001b[0m sample_image_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(sample_image_arr, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the training and testing data\n",
    "train_data = image.ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_data = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_data.flow_from_directory(\n",
    "    directory=r\"C:\\Users\\PUNITH KUMAR\\Desktop\\Brain_Tumour_Detection\\train\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_data.flow_from_directory(\n",
    "    directory=r\"C:\\Users\\PUNITH KUMAR\\Desktop\\Brain_Tumour_Detection\\val\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "test_generator = test_data.flow_from_directory(\n",
    "    directory= r\"C:\\Users\\PUNITH KUMAR\\Desktop\\Brain_Tumour_Detection\\test\",\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Create a ModelCheckpoint callback to save the best model\n",
    "checkpoint = ModelCheckpoint(\"best_model.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate_generator(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6824d351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 280ms/step\n",
      "Predicted class: Healthy\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the best-fit model\n",
    "model1 = load_model(r\"C:\\Users\\PUNITH KUMAR\\Desktop\\New folder\\best_model.h5\")\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = r\"C:\\Users\\PUNITH KUMAR\\Desktop\\New folder\\test\\no\\No13.jpg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "input_arr = image.img_to_array(img)\n",
    "input_arr = np.expand_dims(input_arr, axis=0)\n",
    "input_arr = input_arr / 255.0\n",
    "\n",
    "# Predict the class probabilities\n",
    "probabilities = model1.predict(input_arr)\n",
    "\n",
    "# Obtain the predicted class label\n",
    "predicted_class = 'Tumor' if probabilities[0][0] < 0.5 else 'Healthy'\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae680ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 235ms/step\n",
      "Predicted class: Healthy\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the best-fit model\n",
    "model1 = load_model(r\"C:\\Users\\PUNITH KUMAR\\Desktop\\New folder\\best_model.h5\")\n",
    "\n",
    "# Path to the image you want to predict\n",
    "image_path = r\"C:\\Users\\PUNITH KUMAR\\Desktop\\New folder\\test\\no\\no1107.jpg\"\n",
    "\n",
    "# Load and preprocess the image\n",
    "img = image.load_img(image_path, target_size=(150, 150))\n",
    "input_arr = image.img_to_array(img)\n",
    "input_arr = np.expand_dims(input_arr, axis=0)\n",
    "input_arr = input_arr / 255.0\n",
    "\n",
    "# Predict the class probabilities\n",
    "probabilities = model1.predict(input_arr)\n",
    "\n",
    "# Obtain the predicted class label\n",
    "predicted_class = 'Tumor' if probabilities[0][0] < 0.5 else 'Healthy'\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ef24ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
